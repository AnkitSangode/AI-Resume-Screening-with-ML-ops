model_training:
  logistic_regression:
    C: [0.1, 1, 10]
    solver: [lbfgs, newton-cg, liblinear]

  random_forest:
    n_estimators: [100, 200]
    max_depth: [None, 10]
    min_samples_split: [2, 5]

  svm:
    C: [0.1, 1]
    kernel: [linear, rbf]

deep_learning:
  model:
    layers: [512, 256]
    dropout: 0.3
    activation: relu
    output_activation: softmax
  compile:
    loss: categorical_crossentropy
    optimizer: adam
    metrics: [accuracy]
  training:
    epochs: 10
    batch_size: 32
